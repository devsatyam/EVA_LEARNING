{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "EVA_Session_4_2.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vC1KGoWe6Rcw",
        "colab_type": "text"
      },
      "source": [
        "##Second Iteration"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aNyZv-Ec52ot",
        "colab_type": "text"
      },
      "source": [
        "### **Import Libraries and modules**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3m3w1Cw49Zkt",
        "colab_type": "code",
        "outputId": "d0a0f445-092f-4937-e208-76c9be7596a2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# https://keras.io/\n",
        "!pip install -q keras\n",
        "import keras"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Eso6UHE080D4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten, Add\n",
        "from keras.layers import Convolution2D, MaxPooling2D\n",
        "from keras.utils import np_utils\n",
        "\n",
        "from keras.datasets import mnist"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zByEi95J86RD",
        "colab_type": "text"
      },
      "source": [
        "### Load pre-shuffled MNIST data into train and test sets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7eRM0QWN83PV",
        "colab_type": "code",
        "outputId": "3ce22041-1392-4e3e-a356-989398bc4629",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://s3.amazonaws.com/img-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lqHhymamBXle",
        "colab_type": "text"
      },
      "source": [
        "###Analyzing mnist dataset \n",
        "To proceed further with the convoution, it is always necessary to have a better understanding of how the dataset looks and what could be the prediction dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4a4Be72j8-ZC",
        "colab_type": "code",
        "outputId": "172bb9c5-4109-4482-a37f-94121ed442b5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 303
        }
      },
      "source": [
        "print (X_train.shape)\n",
        "from matplotlib import pyplot as plt\n",
        "%matplotlib inline\n",
        "plt.imshow(X_train[0])\n",
        "plt.imshow(X_train[15])\n",
        "plt.imshow(X_train[500])\n",
        "plt.imshow(X_train[3000])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(60000, 28, 28)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f6afed903c8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_E8ZL9z9DijO",
        "colab_type": "text"
      },
      "source": [
        "###Data Pre-Processing\n",
        "\n",
        "Now we need to reshape the images as the model expects. The last number 1 signifies that the image is in greyscale."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dkmprriw9AnZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train = X_train.reshape(X_train.shape[0], 28, 28,1)\n",
        "X_test = X_test.reshape(X_test.shape[0], 28, 28,1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X2m4YS4E9CRh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train = X_train.astype('float32')\n",
        "X_test = X_test.astype('float32')\n",
        "X_train /= 255\n",
        "X_test /= 255"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ny1tpyKVHUJt",
        "colab_type": "text"
      },
      "source": [
        "We also need to analyzing the Class array and 'one-hot-encode' them to so that our model could make more sense out of it. \n",
        "\n",
        "We can see the sample of class array below:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Mn0vAYD9DvB",
        "colab_type": "code",
        "outputId": "1ce3de0b-dc69-4590-9241-348df7c4797f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "y_train[:10]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([5, 0, 4, 1, 9, 2, 1, 3, 1, 4], dtype=uint8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZG8JiXR39FHC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Convert 1-dimensional class arrays to 10-dimensional class matrices\n",
        "Y_train = np_utils.to_categorical(y_train, 10)\n",
        "Y_test = np_utils.to_categorical(y_test, 10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i-vlW_LhH-yA",
        "colab_type": "text"
      },
      "source": [
        "after processing, we can see that the value of 5 is replaced by an array which signifies its value by keeping 1 in the 6th place (array starts by index 0) and rest of the array as 0."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fYlFRvKS9HMB",
        "colab_type": "code",
        "outputId": "c150c4a8-988a-469f-93d2-d9344a99f7fa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "Y_train[:10]\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
              "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
              "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
              "       [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N7iYzvebJDrl",
        "colab_type": "text"
      },
      "source": [
        "###Building the Model\n",
        "\n",
        "I have built a Sequential model, which allows us to add layers one upon other. We use model.add() to add layers. I am using 3x3 size of kernel for every convolution layer and 2x2 for Maxpooling layers.\n",
        "\n",
        "I have started with building 2 blocks here and there is a transition layer between them:\n",
        "- the first block has 2 convolution layers with 8, 16 and 32 channels. Initially I am trying to create a 7x7 receptive field to ensure the patterns are identified at this point.\n",
        "- then added the transition block, which has Maxpooling followed by 1x1 layer. This block firstly reduces the input size, reducing overall parameters, then overlays all channels using 1x1 convoutions to create 16 such channels.\n",
        "- the 3rd block is again 32 and 64 convolution layers here I suppose the parts of objects are being identified.\n",
        "\n",
        "Further, I have used a 1x1 to reduce the channels, and this will also integrate multiple feature maps into one channel and creating 10 such channels.\n",
        "\n",
        "###UPDATE from First Iteration:\n",
        "I have made 2 updates to the First iteration:\n",
        "- Added Batch Normalization to all convolution layers to improve the accuracy further.\n",
        "- Reduced number of channels from \"32 and 64\" to \"16 and 16 channels\" to reduce the number of parameters."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "osKqT73Q9JJB",
        "colab_type": "code",
        "outputId": "67021858-5f16-4ee9-a64c-8c90f73b5a15",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        }
      },
      "source": [
        "\n",
        "from keras.layers import Activation, BatchNormalization\n",
        "model = Sequential()\n",
        "\n",
        "#Convolution Block 1 \n",
        "model.add(Convolution2D(8, 3, 3, activation='relu', input_shape=(28,28,1))) # 26\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(Convolution2D(16, 3, 3, activation='relu')) # 22\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(Convolution2D(32, 3, 3, activation='relu')) # 9\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "#Transition Block\n",
        "model.add(MaxPooling2D(pool_size=(2, 2))) # 11\n",
        "\n",
        "model.add(Convolution2D(16, 1, 1, activation='relu')) # 11\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "#Convolution Block 2 \n",
        "model.add(Convolution2D(16, 3, 3, activation='relu')) # 7\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(Convolution2D(16, 3, 3, activation='relu')) # 7\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(Convolution2D(10, 1, activation='relu')) #7\n",
        "model.add(Convolution2D(10, 7))\n",
        "model.add(Flatten())\n",
        "model.add(Activation('softmax'))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:6: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(8, (3, 3), activation=\"relu\", input_shape=(28, 28, 1...)`\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:9: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, (3, 3), activation=\"relu\")`\n",
            "  if __name__ == '__main__':\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:12: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), activation=\"relu\")`\n",
            "  if sys.path[0] == '':\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:17: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, (1, 1), activation=\"relu\")`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:20: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, (3, 3), activation=\"relu\")`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:23: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, (3, 3), activation=\"relu\")`\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z7FIvsSjvYKN",
        "colab_type": "code",
        "outputId": "f49d0312-4acc-41ec-b5f0-2d49f68c97ed",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 714
        }
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_1 (Conv2D)            (None, 26, 26, 8)         80        \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 26, 26, 8)         32        \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 24, 24, 16)        1168      \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 24, 24, 16)        64        \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 22, 22, 32)        4640      \n",
            "_________________________________________________________________\n",
            "batch_normalization_3 (Batch (None, 22, 22, 32)        128       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 11, 11, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_4 (Conv2D)            (None, 11, 11, 16)        528       \n",
            "_________________________________________________________________\n",
            "batch_normalization_4 (Batch (None, 11, 11, 16)        64        \n",
            "_________________________________________________________________\n",
            "conv2d_5 (Conv2D)            (None, 9, 9, 16)          2320      \n",
            "_________________________________________________________________\n",
            "batch_normalization_5 (Batch (None, 9, 9, 16)          64        \n",
            "_________________________________________________________________\n",
            "conv2d_6 (Conv2D)            (None, 7, 7, 16)          2320      \n",
            "_________________________________________________________________\n",
            "batch_normalization_6 (Batch (None, 7, 7, 16)          64        \n",
            "_________________________________________________________________\n",
            "conv2d_7 (Conv2D)            (None, 7, 7, 10)          170       \n",
            "_________________________________________________________________\n",
            "conv2d_8 (Conv2D)            (None, 1, 1, 10)          4910      \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 10)                0         \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 10)                0         \n",
            "=================================================================\n",
            "Total params: 16,552\n",
            "Trainable params: 16,344\n",
            "Non-trainable params: 208\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uxI3-ZqS_OO1",
        "colab_type": "text"
      },
      "source": [
        "The total number of parameters have been reduced to **16552** in this iteration while it was 35112 in the first code."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G7AUNI9QHnKE",
        "colab_type": "text"
      },
      "source": [
        "###Compiling the model\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zp6SuGrL9M3h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(loss='categorical_crossentropy',\n",
        "            optimizer='adam',\n",
        "            metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iNhc--VrIgNg",
        "colab_type": "text"
      },
      "source": [
        "###Training the model\n",
        "\n",
        "Finally we have arrived to the step where we are going to train our model. I have run the model with multiple batch sizes and found that it is performing better at *batch_size =64*.\n",
        "\n",
        "The *validation_data* parameter allows the model to perform accuracy test at the end of each epoch.\n",
        "\n",
        "### \\*Observation while comparing First and Second code:\n",
        "- Adding Batch normalization has a slight effect in overall accuracy. \n",
        "- Batch normalization increased each epoch training time. \n",
        "- Since the overfitting can still be seen, we will still try to improve our model in the third iteration."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4xWoKhPY9Of5",
        "colab_type": "code",
        "outputId": "620d4730-e176-417c-e0c4-a9aadb0d7b7c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1856
        }
      },
      "source": [
        "model.fit(X_train, Y_train, batch_size=64, nb_epoch=50, verbose=1, validation_data=(X_test,Y_test))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/50\n",
            "60000/60000 [==============================] - 16s 271us/step - loss: 0.1788 - acc: 0.9457 - val_loss: 0.0535 - val_acc: 0.9828\n",
            "Epoch 2/50\n",
            "60000/60000 [==============================] - 11s 184us/step - loss: 0.0477 - acc: 0.9847 - val_loss: 0.0433 - val_acc: 0.9861\n",
            "Epoch 3/50\n",
            "60000/60000 [==============================] - 11s 183us/step - loss: 0.0367 - acc: 0.9884 - val_loss: 0.0461 - val_acc: 0.9849\n",
            "Epoch 4/50\n",
            "60000/60000 [==============================] - 11s 184us/step - loss: 0.0284 - acc: 0.9909 - val_loss: 0.0315 - val_acc: 0.9894\n",
            "Epoch 5/50\n",
            "60000/60000 [==============================] - 12s 192us/step - loss: 0.0237 - acc: 0.9923 - val_loss: 0.0367 - val_acc: 0.9891\n",
            "Epoch 6/50\n",
            "60000/60000 [==============================] - 12s 198us/step - loss: 0.0234 - acc: 0.9922 - val_loss: 0.0302 - val_acc: 0.9915\n",
            "Epoch 7/50\n",
            "60000/60000 [==============================] - 12s 201us/step - loss: 0.0193 - acc: 0.9937 - val_loss: 0.0383 - val_acc: 0.9877\n",
            "Epoch 8/50\n",
            "60000/60000 [==============================] - 13s 218us/step - loss: 0.0161 - acc: 0.9946 - val_loss: 0.0301 - val_acc: 0.9899\n",
            "Epoch 9/50\n",
            "60000/60000 [==============================] - 12s 194us/step - loss: 0.0147 - acc: 0.9952 - val_loss: 0.0425 - val_acc: 0.9884\n",
            "Epoch 10/50\n",
            "60000/60000 [==============================] - 11s 185us/step - loss: 0.0122 - acc: 0.9960 - val_loss: 0.0502 - val_acc: 0.9865\n",
            "Epoch 11/50\n",
            "60000/60000 [==============================] - 11s 184us/step - loss: 0.0126 - acc: 0.9957 - val_loss: 0.0359 - val_acc: 0.9900\n",
            "Epoch 12/50\n",
            "60000/60000 [==============================] - 11s 186us/step - loss: 0.0117 - acc: 0.9960 - val_loss: 0.0423 - val_acc: 0.9890\n",
            "Epoch 13/50\n",
            "60000/60000 [==============================] - 11s 185us/step - loss: 0.0103 - acc: 0.9964 - val_loss: 0.0302 - val_acc: 0.9908\n",
            "Epoch 14/50\n",
            "60000/60000 [==============================] - 11s 186us/step - loss: 0.0105 - acc: 0.9967 - val_loss: 0.0352 - val_acc: 0.9904\n",
            "Epoch 15/50\n",
            "60000/60000 [==============================] - 12s 208us/step - loss: 0.0070 - acc: 0.9975 - val_loss: 0.0304 - val_acc: 0.9917\n",
            "Epoch 16/50\n",
            "60000/60000 [==============================] - 11s 187us/step - loss: 0.0088 - acc: 0.9966 - val_loss: 0.0362 - val_acc: 0.9905\n",
            "Epoch 17/50\n",
            "60000/60000 [==============================] - 11s 183us/step - loss: 0.0071 - acc: 0.9977 - val_loss: 0.0336 - val_acc: 0.9919\n",
            "Epoch 18/50\n",
            "60000/60000 [==============================] - 11s 184us/step - loss: 0.0065 - acc: 0.9979 - val_loss: 0.0322 - val_acc: 0.9917\n",
            "Epoch 19/50\n",
            "60000/60000 [==============================] - 11s 185us/step - loss: 0.0075 - acc: 0.9976 - val_loss: 0.0311 - val_acc: 0.9922\n",
            "Epoch 20/50\n",
            "60000/60000 [==============================] - 11s 184us/step - loss: 0.0059 - acc: 0.9980 - val_loss: 0.0383 - val_acc: 0.9897\n",
            "Epoch 21/50\n",
            "60000/60000 [==============================] - 11s 185us/step - loss: 0.0061 - acc: 0.9980 - val_loss: 0.0426 - val_acc: 0.9902\n",
            "Epoch 22/50\n",
            "60000/60000 [==============================] - 12s 203us/step - loss: 0.0057 - acc: 0.9980 - val_loss: 0.0368 - val_acc: 0.9913\n",
            "Epoch 23/50\n",
            "60000/60000 [==============================] - 11s 187us/step - loss: 0.0070 - acc: 0.9976 - val_loss: 0.0394 - val_acc: 0.9908\n",
            "Epoch 24/50\n",
            "60000/60000 [==============================] - 11s 185us/step - loss: 0.0053 - acc: 0.9982 - val_loss: 0.0322 - val_acc: 0.9919\n",
            "Epoch 25/50\n",
            "60000/60000 [==============================] - 11s 185us/step - loss: 0.0063 - acc: 0.9979 - val_loss: 0.0362 - val_acc: 0.9911\n",
            "Epoch 26/50\n",
            "60000/60000 [==============================] - 11s 185us/step - loss: 0.0031 - acc: 0.9991 - val_loss: 0.0461 - val_acc: 0.9901\n",
            "Epoch 27/50\n",
            "60000/60000 [==============================] - 11s 186us/step - loss: 0.0043 - acc: 0.9987 - val_loss: 0.0341 - val_acc: 0.9923\n",
            "Epoch 28/50\n",
            "60000/60000 [==============================] - 11s 183us/step - loss: 0.0059 - acc: 0.9981 - val_loss: 0.0466 - val_acc: 0.9898\n",
            "Epoch 29/50\n",
            "60000/60000 [==============================] - 12s 202us/step - loss: 0.0046 - acc: 0.9986 - val_loss: 0.0352 - val_acc: 0.9918\n",
            "Epoch 30/50\n",
            "60000/60000 [==============================] - 11s 190us/step - loss: 0.0042 - acc: 0.9985 - val_loss: 0.0402 - val_acc: 0.9910\n",
            "Epoch 31/50\n",
            "60000/60000 [==============================] - 11s 186us/step - loss: 0.0051 - acc: 0.9983 - val_loss: 0.0400 - val_acc: 0.9923\n",
            "Epoch 32/50\n",
            "60000/60000 [==============================] - 12s 198us/step - loss: 0.0034 - acc: 0.9989 - val_loss: 0.0418 - val_acc: 0.9910\n",
            "Epoch 33/50\n",
            "60000/60000 [==============================] - 11s 186us/step - loss: 0.0037 - acc: 0.9989 - val_loss: 0.0471 - val_acc: 0.9909\n",
            "Epoch 34/50\n",
            "60000/60000 [==============================] - 11s 185us/step - loss: 0.0035 - acc: 0.9990 - val_loss: 0.0408 - val_acc: 0.9915\n",
            "Epoch 35/50\n",
            "60000/60000 [==============================] - 13s 211us/step - loss: 0.0048 - acc: 0.9984 - val_loss: 0.0387 - val_acc: 0.9914\n",
            "Epoch 36/50\n",
            "60000/60000 [==============================] - 12s 207us/step - loss: 0.0029 - acc: 0.9992 - val_loss: 0.0403 - val_acc: 0.9913\n",
            "Epoch 37/50\n",
            "60000/60000 [==============================] - 13s 221us/step - loss: 0.0036 - acc: 0.9988 - val_loss: 0.0505 - val_acc: 0.9896\n",
            "Epoch 38/50\n",
            "60000/60000 [==============================] - 12s 198us/step - loss: 0.0028 - acc: 0.9992 - val_loss: 0.0331 - val_acc: 0.9918\n",
            "Epoch 39/50\n",
            "60000/60000 [==============================] - 12s 199us/step - loss: 0.0043 - acc: 0.9987 - val_loss: 0.0430 - val_acc: 0.9908\n",
            "Epoch 40/50\n",
            "60000/60000 [==============================] - 12s 196us/step - loss: 0.0037 - acc: 0.9988 - val_loss: 0.0431 - val_acc: 0.9906\n",
            "Epoch 41/50\n",
            "60000/60000 [==============================] - 11s 189us/step - loss: 0.0026 - acc: 0.9990 - val_loss: 0.0435 - val_acc: 0.9909\n",
            "Epoch 42/50\n",
            "60000/60000 [==============================] - 11s 188us/step - loss: 0.0033 - acc: 0.9989 - val_loss: 0.0486 - val_acc: 0.9908\n",
            "Epoch 43/50\n",
            "60000/60000 [==============================] - 13s 209us/step - loss: 0.0040 - acc: 0.9987 - val_loss: 0.0415 - val_acc: 0.9923\n",
            "Epoch 44/50\n",
            "60000/60000 [==============================] - 11s 190us/step - loss: 0.0021 - acc: 0.9993 - val_loss: 0.0366 - val_acc: 0.9921\n",
            "Epoch 45/50\n",
            "60000/60000 [==============================] - 11s 189us/step - loss: 0.0031 - acc: 0.9991 - val_loss: 0.0428 - val_acc: 0.9908\n",
            "Epoch 46/50\n",
            "60000/60000 [==============================] - 11s 189us/step - loss: 0.0049 - acc: 0.9984 - val_loss: 0.0551 - val_acc: 0.9896\n",
            "Epoch 47/50\n",
            "60000/60000 [==============================] - 11s 188us/step - loss: 0.0021 - acc: 0.9994 - val_loss: 0.0547 - val_acc: 0.9902\n",
            "Epoch 48/50\n",
            "60000/60000 [==============================] - 11s 189us/step - loss: 0.0029 - acc: 0.9992 - val_loss: 0.0459 - val_acc: 0.9896\n",
            "Epoch 49/50\n",
            "60000/60000 [==============================] - 11s 191us/step - loss: 0.0031 - acc: 0.9990 - val_loss: 0.0402 - val_acc: 0.9916\n",
            "Epoch 50/50\n",
            "60000/60000 [==============================] - 13s 210us/step - loss: 0.0036 - acc: 0.9988 - val_loss: 0.0467 - val_acc: 0.9917\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f6ade5878d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AtsH-lLk-eLb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "score = model.evaluate(X_test, Y_test, verbose=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mkX8JMv79q9r",
        "colab_type": "code",
        "outputId": "ab718194-5992-4dd5-91c4-84f7d959adf1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(score)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.046668703876414495, 0.9917]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OCWoJkwE9suh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_pred = model.predict(X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ym7iCFBm9uBs",
        "colab_type": "code",
        "outputId": "7d167bd6-8555-4ccf-87f1-13d204057055",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 493
        }
      },
      "source": [
        "print(y_pred[:9])\n",
        "print(y_test[:9])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[8.13155070e-17 3.77470436e-25 2.63226468e-10 5.58302861e-13\n",
            "  3.27340572e-19 3.18425742e-21 0.00000000e+00 1.00000000e+00\n",
            "  4.34926267e-20 2.99587883e-13]\n",
            " [9.61302774e-14 1.27816041e-16 1.00000000e+00 4.01692990e-23\n",
            "  7.57738420e-25 1.08445718e-26 1.78962031e-17 1.59659716e-26\n",
            "  2.25833601e-23 4.90156750e-35]\n",
            " [7.63457795e-16 1.00000000e+00 4.70331612e-14 2.93141042e-18\n",
            "  1.76131665e-10 1.07147845e-13 4.38089940e-13 2.26358407e-12\n",
            "  1.23623375e-17 1.52129129e-15]\n",
            " [9.99998689e-01 3.95410204e-32 8.68793488e-17 2.16437586e-14\n",
            "  2.78018018e-17 1.26289861e-13 1.33680021e-06 4.31889759e-22\n",
            "  1.33204103e-13 7.09098578e-12]\n",
            " [9.99649891e-22 1.63187099e-22 1.49578458e-26 3.01178734e-33\n",
            "  1.00000000e+00 3.66890733e-27 2.95265987e-15 1.32440608e-22\n",
            "  4.40171965e-21 7.69169814e-16]\n",
            " [7.59176996e-16 1.00000000e+00 1.44979596e-13 5.00943309e-18\n",
            "  1.38492509e-10 1.16572562e-14 7.53516614e-15 2.79867685e-10\n",
            "  1.82836747e-16 1.34293355e-16]\n",
            " [1.05835615e-30 2.22134920e-15 1.51890439e-27 2.55308544e-28\n",
            "  1.00000000e+00 1.20724786e-22 6.94408651e-35 7.21545512e-18\n",
            "  9.02481333e-15 5.82798621e-13]\n",
            " [1.24588910e-21 7.42157826e-28 2.58658892e-23 3.23376962e-23\n",
            "  6.62266145e-11 1.03424801e-18 4.77003328e-26 1.21234527e-18\n",
            "  3.53630310e-20 1.00000000e+00]\n",
            " [6.19231055e-10 4.78692192e-31 2.47751424e-19 1.53517669e-25\n",
            "  1.18965818e-20 2.45660520e-03 9.97482359e-01 2.43784498e-29\n",
            "  6.10522548e-05 5.96312843e-12]]\n",
            "[7 2 1 0 4 1 4 9 5]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CT--y98_dr2T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "layer_dict = dict([(layer.name, layer) for layer in model.layers])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2GY4Upv4dsUR",
        "colab_type": "code",
        "outputId": "8671bd20-1616-4b61-9e8e-d9f0521634c1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 316
        }
      },
      "source": [
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "from keras import backend as K\n",
        "%matplotlib inline\n",
        "# util function to convert a tensor into a valid image\n",
        "def deprocess_image(x):\n",
        "    # normalize tensor: center on 0., ensure std is 0.1\n",
        "    x -= x.mean()\n",
        "    x /= (x.std() + 1e-5)\n",
        "    x *= 0.1\n",
        "\n",
        "    # clip to [0, 1]\n",
        "    x += 0.5\n",
        "    x = np.clip(x, 0, 1)\n",
        "\n",
        "    # convert to RGB array\n",
        "    x *= 255\n",
        "    #x = x.transpose((1, 2, 0))\n",
        "    x = np.clip(x, 0, 255).astype('uint8')\n",
        "    return x\n",
        "\n",
        "def vis_img_in_filter(img = np.array(X_train[2]).reshape((1, 28, 28, 1)).astype(np.float64), \n",
        "                      layer_name = 'conv2d_14'):\n",
        "    layer_output = layer_dict[layer_name].output\n",
        "    img_ascs = list()\n",
        "    for filter_index in range(layer_output.shape[3]):\n",
        "        # build a loss function that maximizes the activation\n",
        "        # of the nth filter of the layer considered\n",
        "        loss = K.mean(layer_output[:, :, :, filter_index])\n",
        "\n",
        "        # compute the gradient of the input picture wrt this loss\n",
        "        grads = K.gradients(loss, model.input)[0]\n",
        "\n",
        "        # normalization trick: we normalize the gradient\n",
        "        grads /= (K.sqrt(K.mean(K.square(grads))) + 1e-5)\n",
        "\n",
        "        # this function returns the loss and grads given the input picture\n",
        "        iterate = K.function([model.input], [loss, grads])\n",
        "\n",
        "        # step size for gradient ascent\n",
        "        step = 5.\n",
        "\n",
        "        img_asc = np.array(img)\n",
        "        # run gradient ascent for 20 steps\n",
        "        for i in range(20):\n",
        "            loss_value, grads_value = iterate([img_asc])\n",
        "            img_asc += grads_value * step\n",
        "\n",
        "        img_asc = img_asc[0]\n",
        "        img_ascs.append(deprocess_image(img_asc).reshape((28, 28)))\n",
        "        \n",
        "    if layer_output.shape[3] >= 35:\n",
        "        plot_x, plot_y = 6, 6\n",
        "    elif layer_output.shape[3] >= 23:\n",
        "        plot_x, plot_y = 4, 6\n",
        "    elif layer_output.shape[3] >= 11:\n",
        "        plot_x, plot_y = 2, 6\n",
        "    else:\n",
        "        plot_x, plot_y = 1, 2\n",
        "    fig, ax = plt.subplots(plot_x, plot_y, figsize = (12, 12))\n",
        "    ax[0, 0].imshow(img.reshape((28, 28)), cmap = 'gray')\n",
        "    ax[0, 0].set_title('Input image')\n",
        "    fig.suptitle('Input image and %s filters' % (layer_name,))\n",
        "    fig.tight_layout(pad = 0.3, rect = [0, 0, 0.9, 0.9])\n",
        "    for (x, y) in [(i, j) for i in range(plot_x) for j in range(plot_y)]:\n",
        "        if x == 0 and y == 0:\n",
        "            continue\n",
        "        ax[x, y].imshow(img_ascs[x * plot_y + y - 1], cmap = 'gray')\n",
        "        ax[x, y].set_title('filter %d' % (x * plot_y + y - 1))\n",
        "\n",
        "vis_img_in_filter()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-19229f66b51a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     69\u001b[0m         \u001b[0max\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_title\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'filter %d'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mplot_y\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m \u001b[0mvis_img_in_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-19-19229f66b51a>\u001b[0m in \u001b[0;36mvis_img_in_filter\u001b[0;34m(img, layer_name)\u001b[0m\n\u001b[1;32m     22\u001b[0m def vis_img_in_filter(img = np.array(X_train[2]).reshape((1, 28, 28, 1)).astype(np.float64), \n\u001b[1;32m     23\u001b[0m                       layer_name = 'conv2d_14'):\n\u001b[0;32m---> 24\u001b[0;31m     \u001b[0mlayer_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlayer_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m     \u001b[0mimg_ascs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mfilter_index\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'conv2d_14'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9tvptcn8dxvp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}
