{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "EVA_Session_4_1.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vC1KGoWe6Rcw",
        "colab_type": "text"
      },
      "source": [
        "##First Iteration"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aNyZv-Ec52ot",
        "colab_type": "text"
      },
      "source": [
        "### **Import Libraries and modules**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3m3w1Cw49Zkt",
        "colab_type": "code",
        "outputId": "d50278c8-5b6b-44e6-e740-5e663ff14daf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# https://keras.io/\n",
        "!pip install -q keras\n",
        "import keras"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Eso6UHE080D4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten, Add\n",
        "from keras.layers import Convolution2D, MaxPooling2D\n",
        "from keras.utils import np_utils\n",
        "\n",
        "from keras.datasets import mnist"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zByEi95J86RD",
        "colab_type": "text"
      },
      "source": [
        "### Load pre-shuffled MNIST data into train and test sets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7eRM0QWN83PV",
        "colab_type": "code",
        "outputId": "01e49cc5-6e6c-4956-ffb0-aa70b801a852",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://s3.amazonaws.com/img-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 2s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lqHhymamBXle",
        "colab_type": "text"
      },
      "source": [
        "###Analyzing mnist dataset \n",
        "To proceed further with the convoution, it is always necessary to have a better understanding of how the dataset looks and what could be the prediction dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4a4Be72j8-ZC",
        "colab_type": "code",
        "outputId": "ddb1ee82-6013-488e-cdf4-55758a67f4f6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 303
        }
      },
      "source": [
        "print (X_train.shape)\n",
        "from matplotlib import pyplot as plt\n",
        "%matplotlib inline\n",
        "plt.imshow(X_train[0])\n",
        "plt.imshow(X_train[15])\n",
        "plt.imshow(X_train[500])\n",
        "plt.imshow(X_train[3000])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(60000, 28, 28)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7fc383c73390>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAADrhJREFUeJzt3X2QVfV9x/HPF1hAeWhBCKXIBBEM\nw5CKmQ3alKS2NFYZDdp0GGjN4AzNZjraKcZO49jM1KadCekkcczUSbJEKhqjsUUqnZpWpabWlm5Z\nH4IPhIdQGMGFBTEBSgP78O0fe3BW3fO7l/t07vJ9v2Z29u75nnPPd+7w4Zx7fveen7m7AMQzougG\nABSD8ANBEX4gKMIPBEX4gaAIPxAU4QeCIvxAUIQfCGpUI3c22sb4WI1r5C6BUH6u/9UZP23lrFtV\n+M3sWkn3Shop6Tvuvja1/liN05W2pJpdAkjo8C1lr1vxab+ZjZR0n6TrJM2XtNLM5lf6fAAaq5r3\n/Isk7XH3ve5+RtKjkpbVpi0A9VZN+GdIemPQ3weyZe9iZm1m1mlmnT06XcXuANRS3a/2u3u7u7e6\ne2uLxtR7dwDKVE34D0qaOejvi7NlAIaBasK/TdJcM7vEzEZLWiFpc23aAlBvFQ/1uXuvmd0m6V80\nMNS33t1fq1lnAOqqqnF+d39S0pM16gVAA/HxXiAowg8ERfiBoAg/EBThB4Ii/EBQhB8IivADQRF+\nICjCDwRF+IGgCD8QFOEHgiL8QFCEHwiK8ANBEX4gKMIPBEX4gaAIPxAU4QeCIvxAUIQfCIrwA0ER\nfiAowg8ERfiBoAg/EBThB4KqapZeM9sn6YSkPkm97t5ai6YA1F9V4c/8hrsfrcHzAGggTvuBoKoN\nv0t6ysxeMLO2WjQEoDGqPe1f7O4HzewDkp42sx+7+3ODV8j+U2iTpLG6sMrdAaiVqo787n4w+90t\naZOkRUOs0+7ure7e2qIx1ewOQA1VHH4zG2dmE84+lnSNpFdr1RiA+qrmtH+apE1mdvZ5vufu/1yT\nrgDUXcXhd/e9ki6vYS8owKjZs5L1N5f+crI+4YauZP3ZBRvPtaV3jLT0iWmf9yfr85+/Jbd26RdP\npp97995k/XzAUB8QFOEHgiL8QFCEHwiK8ANBEX4gqFp8qw8FGzFhQm7tyIoFyW1vXvODZP2PfvHx\nino66x9PTcytdffm18ox1s4k668vfiC3dvmnb0tuO2MtQ30AzlOEHwiK8ANBEX4gKMIPBEX4gaAI\nPxAU4/zDgLWmx+qP/9Wp3FrHh+9Lbvt/nh4rv7xjdbI+tT19a7YLtv0kt9b31rHktqWcXvrRZP33\n1307tzZ1ycH0k6+tpKPhhSM/EBThB4Ii/EBQhB8IivADQRF+ICjCDwTFOH8TOLn8qmT9S19el6xf\nPbYnt/bA8fStt7+99qZkfcaGrcl6KX1VbZ1mt3dXvO3hH85I1mdqf8XPPVxw5AeCIvxAUIQfCIrw\nA0ERfiAowg8ERfiBoMzd0yuYrZd0vaRud1+QLZss6fuSZknaJ2m5u79damcTbbJfaUuqbHn48Y+l\nZzL/0nfXJ+sfHWPJ+tyNf5hbm/fFHclt+44fT9ab2ce3/zxZ7/P8Y9vW1vHJbb0nfZ+DZtXhW3Tc\nj6X/wWTKOfI/IOna9yy7U9IWd58raUv2N4BhpGT43f05Se+95coySRuyxxsk3VjjvgDUWaXv+ae5\ne1f2+JCkaTXqB0CDVH3BzwcuGuReODCzNjPrNLPOHp2udncAaqTS8B82s+mSlP3O/YaFu7e7e6u7\nt7ZoTIW7A1BrlYZ/s6RV2eNVkp6oTTsAGqVk+M3sEUlbJX3IzA6Y2WoN3Nj4k2a2W9JvKcSNjoHz\nS8nv87v7ypxSvAH7Co398uFkvdQ4/qf3XJesz13TmVvr66/nN+qLtfF/Fibr3738b3NrD37l9uS2\ncz7/XxX1NJzwCT8gKMIPBEX4gaAIPxAU4QeCIvxAUNy6uwaOtv1qsv7M7K8l62/3p79W/eb62cn6\npP70UOL56qdvpb+WO68l/xOl1338peS2uyvqaHjhyA8ERfiBoAg/EBThB4Ii/EBQhB8IivADQTHO\nXyYblf9SzV21M7ntxBFjk/V5D9+arM+ucprs4ergFz6WrP/4t+8t8Qwjcytbv/OR5JZTdP6/5hz5\ngaAIPxAU4QeCIvxAUIQfCIrwA0ERfiAoxvnLtPMb+ePCe2Z9K7ntVS+tSNbn3P2jZL0/WR2+RkyY\nkKz/yqfS04uPSozjS9INu67PrU1Z99/JbSPgyA8ERfiBoAg/EBThB4Ii/EBQhB8IivADQZUc5zez\n9ZKul9Tt7guyZXdL+qykI9lqd7n7k/VqshncsCh9n/cU+7uLkvX+U7sqfu5mZy2jc2tnNk1KbvvQ\nrH+oat9HT43LrU06j6cuL1c5R/4HJF07xPJ73H1h9nNeBx84H5UMv7s/J+lYA3oB0EDVvOe/zcy2\nm9l6M0ufvwFoOpWG/5uSLpW0UFKXpNzJ6Myszcw6zayzR6cr3B2AWqso/O5+2N373L1f0jpJixLr\ntrt7q7u3tih/4kQAjVVR+M1s+qA/b5L0am3aAdAo5Qz1PSLpaklTzOyApD+XdLWZLZTkkvZJ+lwd\newRQByXD7+4rh1h8fx16KdSoSz6YrN980d8nqunvlU99Zn+y3pusNreREycm6z2bfiG39tS89Dj+\nSEufmPZ5+k4HR7rze+MKNZ/wA8Ii/EBQhB8IivADQRF+ICjCDwTFrbvPOtOTLB/qzR+y0uiTyW13\nrkkPI37oG+n/g3vfOJCsp9iYEp+qXDAnWd51y/hk/S+vSQ2BSr87/lBubd6/fTa57bOL/yZZnzwi\n/+vCknTxZv55p3DkB4Ii/EBQhB8IivADQRF+ICjCDwRF+IGgGAjN9B58M1m/Y+Oq3Npv3nxPctud\nv3dfsv7D32lJ1p94O3968FImjjqVrP/F1Icqfm5J6u5LP/+ir/5pbm3Ov76d3LZ/cXrff9L1iWT9\nwk0d6ScIjiM/EBThB4Ii/EBQhB8IivADQRF+ICjCDwTFOH+ZZt+5Nbf263tvT277+TseS9ZXjD+S\nrF89vfLx6s/sW5Ksz3mhLVmf3JH+DMK0R19L1n/p+H/m1t76p7nJbWeMvDBZ/8FLH07WL9O2ZD06\njvxAUIQfCIrwA0ERfiAowg8ERfiBoAg/EFTJcX4zmynpQUnTJLmkdne/18wmS/q+pFmS9kla7u7p\nL2ifp6a0538GQJIefmxBsv69Cy6oZTvv0nfkaLJ+WW9ndc9foj5i7Njc2h/M/o+q9n3JY+kpupFW\nzpG/V9Id7j5f0lWSbjWz+ZLulLTF3edK2pL9DWCYKBl+d+9y9xezxyck7ZA0Q9IySRuy1TZIurFe\nTQKovXN6z29msyRdIalD0jR378pKhzTwtgDAMFF2+M1svKSNkta4+/HBNXd3DVwPGGq7NjPrNLPO\nHp2uqlkAtVNW+M2sRQPBf9jdH88WHzaz6Vl9uqTuobZ193Z3b3X31haVmDQSQMOUDL+ZmaT7Je1w\n968PKm2WdPaWtqskPVH79gDUSzlf6f01SZ+R9IqZvZwtu0vSWkmPmdlqSfslLa9Pi8Nf309/ll6h\nVH0YO3zLFbm11RPzv+4rSet+NjNZH9OxK1lnIDCtZPjd/XlJllNOf1kcQNPiE35AUIQfCIrwA0ER\nfiAowg8ERfiBoLh1N+pq9KfStyVP+crzS5P1y05wa+5qcOQHgiL8QFCEHwiK8ANBEX4gKMIPBEX4\ngaAY50ddLfrA/oq3HdOVnh4c1eHIDwRF+IGgCD8QFOEHgiL8QFCEHwiK8ANBEX4gKMIPBEX4gaAI\nPxAU4QeCIvxAUIQfCIrwA0GVDL+ZzTSzZ83sdTN7zcz+OFt+t5kdNLOXs5/0TdYBNJVybubRK+kO\nd3/RzCZIesHMns5q97j7V+vXHoB6KRl+d++S1JU9PmFmOyTNqHdjAOrrnN7zm9ksSVdI6sgW3WZm\n281svZlNytmmzcw6zayzR6erahZA7ZQdfjMbL2mjpDXuflzSNyVdKmmhBs4MvjbUdu7e7u6t7t7a\nojE1aBlALZQVfjNr0UDwH3b3xyXJ3Q+7e5+790taJ2lR/doEUGvlXO03SfdL2uHuXx+0fPqg1W6S\n9Grt2wNQL+bu6RXMFkv6d0mvSOrPFt8laaUGTvld0j5Jn8suDuaaaJP9SltSZcsA8nT4Fh33Y1bO\nuuVc7X9e0lBP9uS5NgagefAJPyAowg8ERfiBoAg/EBThB4Ii/EBQhB8IivADQRF+ICjCDwRF+IGg\nCD8QFOEHgiL8QFAlv89f052ZHZG0f9CiKZKONqyBc9OsvTVrXxK9VaqWvX3Q3aeWs2JDw/++nZt1\nuntrYQ0kNGtvzdqXRG+VKqo3TvuBoAg/EFTR4W8veP8pzdpbs/Yl0VulCumt0Pf8AIpT9JEfQEEK\nCb+ZXWtmO81sj5ndWUQPecxsn5m9ks083FlwL+vNrNvMXh20bLKZPW1mu7PfQ06TVlBvTTFzc2Jm\n6UJfu2ab8brhp/1mNlLSLkmflHRA0jZJK9399YY2ksPM9klqdffCx4TN7BOSTkp60N0XZMv+WtIx\nd1+b/cc5yd2/0CS93S3pZNEzN2cTykwfPLO0pBsl3aICX7tEX8tVwOtWxJF/kaQ97r7X3c9IelTS\nsgL6aHru/pykY+9ZvEzShuzxBg3842m4nN6agrt3ufuL2eMTks7OLF3oa5foqxBFhH+GpDcG/X1A\nzTXlt0t6ysxeMLO2opsZwrRBMyMdkjStyGaGUHLm5kZ6z8zSTfPaVTLjda1xwe/9Frv7RyRdJ+nW\n7PS2KfnAe7ZmGq4pa+bmRhliZul3FPnaVTrjda0VEf6DkmYO+vvibFlTcPeD2e9uSZvUfLMPHz47\nSWr2u7vgft7RTDM3DzWztJrgtWumGa+LCP82SXPN7BIzGy1phaTNBfTxPmY2LrsQIzMbJ+kaNd/s\nw5slrcoer5L0RIG9vEuzzNycN7O0Cn7tmm7Ga3dv+I+kpRq44v8TSX9WRA85fc2W9KPs57Wie5P0\niAZOA3s0cG1ktaSLJG2RtFvSM5ImN1FvD2lgNuftGgja9IJ6W6yBU/rtkl7OfpYW/dol+irkdeMT\nfkBQXPADgiL8QFCEHwiK8ANBEX4gKMIPBEX4gaAIPxDU/wM5VWnj2m+9SAAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_E8ZL9z9DijO",
        "colab_type": "text"
      },
      "source": [
        "###Data Pre-Processing\n",
        "\n",
        "Now we need to reshape the images as the model expects. The last number 1 signifies that the image is in greyscale."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dkmprriw9AnZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train = X_train.reshape(X_train.shape[0], 28, 28,1)\n",
        "X_test = X_test.reshape(X_test.shape[0], 28, 28,1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X2m4YS4E9CRh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train = X_train.astype('float32')\n",
        "X_test = X_test.astype('float32')\n",
        "X_train /= 255\n",
        "X_test /= 255"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ny1tpyKVHUJt",
        "colab_type": "text"
      },
      "source": [
        "We also need to analyzing the Class array and 'one-hot-encode' them to so that our model could make more sense out of it. \n",
        "\n",
        "We can see the sample of class array below:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Mn0vAYD9DvB",
        "colab_type": "code",
        "outputId": "976ecb2d-b3bd-47c5-fbd0-1e64dcc062f2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "y_train[:10]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([5, 0, 4, 1, 9, 2, 1, 3, 1, 4], dtype=uint8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZG8JiXR39FHC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Convert 1-dimensional class arrays to 10-dimensional class matrices\n",
        "Y_train = np_utils.to_categorical(y_train, 10)\n",
        "Y_test = np_utils.to_categorical(y_test, 10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i-vlW_LhH-yA",
        "colab_type": "text"
      },
      "source": [
        "after processing, we can see that the value of 5 is replaced by an array which signifies its value by keeping 1 in the 6th place (array starts by index 0) and rest of the array as 0."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fYlFRvKS9HMB",
        "colab_type": "code",
        "outputId": "e105a329-5730-4140-8ab3-a740408591d5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "Y_train[:10]\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
              "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
              "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
              "       [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N7iYzvebJDrl",
        "colab_type": "text"
      },
      "source": [
        "###Building the Model\n",
        "\n",
        "I have built a Sequential model, which allows us to add layers one upon other. We use model.add() to add layers. I am using 3x3 size of kernel for every convolution layer and 2x2 for Maxpooling layers.\n",
        "\n",
        "I have started with building 2 blocks here and there is a transition layer between them:\n",
        "- the first block has 2 convolution layers with 8, 16 and 32 channels. Initially I am trying to create a 7x7 receptive field to ensure the patterns are identified at this point.\n",
        "- then added the transition block, which has Maxpooling followed by 1x1 layer. This block firstly reduces the input size, reducing overall parameters, then overlays all channels using 1x1 convoutions to create 16 such channels.\n",
        "- the 3rd block is again 32 and 64 convolution layers here I suppose the parts of objects are being identified.\n",
        "\n",
        "Further, I have used a 1x1 to reduce the channels, and this will also integrate multiple feature maps into one channel and creating 10 such channels."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "osKqT73Q9JJB",
        "colab_type": "code",
        "outputId": "5eafb197-4cfe-4976-c949-f027b74a577f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 292
        }
      },
      "source": [
        "from keras.layers import Activation\n",
        "model = Sequential()\n",
        "\n",
        "\n",
        "#Convolution Block 1 \n",
        "model.add(Convolution2D(8, 3, 3, activation='relu', input_shape=(28,28,1))) # 26\n",
        "\n",
        "model.add(Convolution2D(16, 3, 3, activation='relu')) # 24\n",
        "model.add(Convolution2D(32, 3, 3, activation='relu')) # 22\n",
        "\n",
        "#Transition Block\n",
        "model.add(MaxPooling2D(pool_size=(2, 2))) # 11\n",
        "model.add(Convolution2D(16, 1, 1, activation='relu')) # 11\n",
        "\n",
        "#Convoltution Block 2\n",
        "model.add(Convolution2D(32, 3, 3, activation='relu')) # 9\n",
        "model.add(Convolution2D(64, 3, 3, activation='relu')) # 7\n",
        "\n",
        "model.add(Convolution2D(10, 1, activation='relu')) #7\n",
        "model.add(Convolution2D(10, 7))\n",
        "model.add(Flatten())\n",
        "model.add(Activation('softmax'))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:5: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(8, (3, 3), activation=\"relu\", input_shape=(28, 28, 1...)`\n",
            "  \"\"\"\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:7: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, (3, 3), activation=\"relu\")`\n",
            "  import sys\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:8: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), activation=\"relu\")`\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:11: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, (1, 1), activation=\"relu\")`\n",
            "  # This is added back by InteractiveShellApp.init_path()\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:13: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), activation=\"relu\")`\n",
            "  del sys.path[0]\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:14: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (3, 3), activation=\"relu\")`\n",
            "  \n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z7FIvsSjvYKN",
        "colab_type": "code",
        "outputId": "5cfa9548-fe6e-40ea-c4e6-68c80ba71e8c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 510
        }
      },
      "source": [
        "model.summary() "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_1 (Conv2D)            (None, 26, 26, 8)         80        \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 24, 24, 16)        1168      \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 22, 22, 32)        4640      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 11, 11, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_4 (Conv2D)            (None, 11, 11, 16)        528       \n",
            "_________________________________________________________________\n",
            "conv2d_5 (Conv2D)            (None, 9, 9, 32)          4640      \n",
            "_________________________________________________________________\n",
            "conv2d_6 (Conv2D)            (None, 7, 7, 64)          18496     \n",
            "_________________________________________________________________\n",
            "conv2d_7 (Conv2D)            (None, 7, 7, 10)          650       \n",
            "_________________________________________________________________\n",
            "conv2d_8 (Conv2D)            (None, 1, 1, 10)          4910      \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 10)                0         \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 10)                0         \n",
            "=================================================================\n",
            "Total params: 35,112\n",
            "Trainable params: 35,112\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G7AUNI9QHnKE",
        "colab_type": "text"
      },
      "source": [
        "###Compiling the model\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zp6SuGrL9M3h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(loss='categorical_crossentropy',\n",
        "            optimizer='adam',\n",
        "            metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iNhc--VrIgNg",
        "colab_type": "text"
      },
      "source": [
        "###Training the model\n",
        "\n",
        "Finally we have arrived to the step where we are going to train our model. I have run the model with multiple batch sizes and found that it is performing better at *batch_size =64*.\n",
        "\n",
        "The *validation_data* parameter allows the model to perform accuracy test at the end of each epoch.\n",
        "\n",
        "From the below we see that the accuracy is varying between 98.8% to 99.2% with this model. By seeing the variation in 50 epochs we can say that it is not the best models to achieve 99.4% accuracy target. We have also observed that the model is overfitting as the gap between Train and valiadtion accuracy is increasing."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4xWoKhPY9Of5",
        "colab_type": "code",
        "outputId": "be742773-2649-417a-d666-c24dd32b71ee",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1856
        }
      },
      "source": [
        "model.fit(X_train, Y_train, batch_size=64, nb_epoch=50, verbose=1, validation_data=(X_test,Y_test))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/50\n",
            "60000/60000 [==============================] - 11s 178us/step - loss: 0.2108 - acc: 0.9331 - val_loss: 0.0579 - val_acc: 0.9817\n",
            "Epoch 2/50\n",
            "60000/60000 [==============================] - 6s 95us/step - loss: 0.0604 - acc: 0.9817 - val_loss: 0.0422 - val_acc: 0.9855\n",
            "Epoch 3/50\n",
            "60000/60000 [==============================] - 6s 97us/step - loss: 0.0455 - acc: 0.9861 - val_loss: 0.0368 - val_acc: 0.9879\n",
            "Epoch 4/50\n",
            "60000/60000 [==============================] - 6s 95us/step - loss: 0.0376 - acc: 0.9885 - val_loss: 0.0314 - val_acc: 0.9899\n",
            "Epoch 5/50\n",
            "60000/60000 [==============================] - 6s 97us/step - loss: 0.0324 - acc: 0.9895 - val_loss: 0.0377 - val_acc: 0.9887\n",
            "Epoch 6/50\n",
            "60000/60000 [==============================] - 6s 106us/step - loss: 0.0296 - acc: 0.9904 - val_loss: 0.0318 - val_acc: 0.9898\n",
            "Epoch 7/50\n",
            "60000/60000 [==============================] - 6s 100us/step - loss: 0.0254 - acc: 0.9919 - val_loss: 0.0362 - val_acc: 0.9882\n",
            "Epoch 8/50\n",
            "60000/60000 [==============================] - 6s 95us/step - loss: 0.0227 - acc: 0.9926 - val_loss: 0.0256 - val_acc: 0.9923\n",
            "Epoch 9/50\n",
            "60000/60000 [==============================] - 6s 95us/step - loss: 0.0195 - acc: 0.9939 - val_loss: 0.0338 - val_acc: 0.9902\n",
            "Epoch 10/50\n",
            "60000/60000 [==============================] - 6s 95us/step - loss: 0.0183 - acc: 0.9941 - val_loss: 0.0293 - val_acc: 0.9920\n",
            "Epoch 11/50\n",
            "60000/60000 [==============================] - 6s 95us/step - loss: 0.0149 - acc: 0.9952 - val_loss: 0.0287 - val_acc: 0.9911\n",
            "Epoch 12/50\n",
            "60000/60000 [==============================] - 6s 94us/step - loss: 0.0137 - acc: 0.9955 - val_loss: 0.0552 - val_acc: 0.9860\n",
            "Epoch 13/50\n",
            "60000/60000 [==============================] - 6s 93us/step - loss: 0.0137 - acc: 0.9954 - val_loss: 0.0284 - val_acc: 0.9918\n",
            "Epoch 14/50\n",
            "60000/60000 [==============================] - 6s 93us/step - loss: 0.0116 - acc: 0.9963 - val_loss: 0.0360 - val_acc: 0.9906\n",
            "Epoch 15/50\n",
            "60000/60000 [==============================] - 6s 93us/step - loss: 0.0104 - acc: 0.9967 - val_loss: 0.0413 - val_acc: 0.9890\n",
            "Epoch 16/50\n",
            "60000/60000 [==============================] - 6s 93us/step - loss: 0.0083 - acc: 0.9972 - val_loss: 0.0486 - val_acc: 0.9906\n",
            "Epoch 17/50\n",
            "60000/60000 [==============================] - 6s 93us/step - loss: 0.0106 - acc: 0.9965 - val_loss: 0.0344 - val_acc: 0.9904\n",
            "Epoch 18/50\n",
            "60000/60000 [==============================] - 6s 93us/step - loss: 0.0078 - acc: 0.9973 - val_loss: 0.0581 - val_acc: 0.9884\n",
            "Epoch 19/50\n",
            "60000/60000 [==============================] - 6s 100us/step - loss: 0.0084 - acc: 0.9972 - val_loss: 0.0501 - val_acc: 0.9887\n",
            "Epoch 20/50\n",
            "60000/60000 [==============================] - 6s 104us/step - loss: 0.0076 - acc: 0.9975 - val_loss: 0.0441 - val_acc: 0.9898\n",
            "Epoch 21/50\n",
            "60000/60000 [==============================] - 6s 98us/step - loss: 0.0077 - acc: 0.9972 - val_loss: 0.0404 - val_acc: 0.9903\n",
            "Epoch 22/50\n",
            "60000/60000 [==============================] - 6s 92us/step - loss: 0.0063 - acc: 0.9980 - val_loss: 0.0362 - val_acc: 0.9910\n",
            "Epoch 23/50\n",
            "60000/60000 [==============================] - 6s 93us/step - loss: 0.0065 - acc: 0.9979 - val_loss: 0.0380 - val_acc: 0.9908\n",
            "Epoch 24/50\n",
            "60000/60000 [==============================] - 6s 92us/step - loss: 0.0065 - acc: 0.9978 - val_loss: 0.0419 - val_acc: 0.9921\n",
            "Epoch 25/50\n",
            "60000/60000 [==============================] - 6s 93us/step - loss: 0.0064 - acc: 0.9979 - val_loss: 0.0434 - val_acc: 0.9905\n",
            "Epoch 26/50\n",
            "60000/60000 [==============================] - 6s 93us/step - loss: 0.0059 - acc: 0.9979 - val_loss: 0.0506 - val_acc: 0.9891\n",
            "Epoch 27/50\n",
            "60000/60000 [==============================] - 6s 93us/step - loss: 0.0054 - acc: 0.9984 - val_loss: 0.0477 - val_acc: 0.9915\n",
            "Epoch 28/50\n",
            "60000/60000 [==============================] - 6s 92us/step - loss: 0.0058 - acc: 0.9981 - val_loss: 0.0405 - val_acc: 0.9912\n",
            "Epoch 29/50\n",
            "60000/60000 [==============================] - 6s 93us/step - loss: 0.0040 - acc: 0.9987 - val_loss: 0.0480 - val_acc: 0.9893\n",
            "Epoch 30/50\n",
            "60000/60000 [==============================] - 6s 92us/step - loss: 0.0069 - acc: 0.9978 - val_loss: 0.0510 - val_acc: 0.9891\n",
            "Epoch 31/50\n",
            "60000/60000 [==============================] - 6s 93us/step - loss: 0.0047 - acc: 0.9983 - val_loss: 0.0462 - val_acc: 0.9913\n",
            "Epoch 32/50\n",
            "60000/60000 [==============================] - 6s 92us/step - loss: 0.0050 - acc: 0.9985 - val_loss: 0.0459 - val_acc: 0.9896\n",
            "Epoch 33/50\n",
            "60000/60000 [==============================] - 6s 93us/step - loss: 0.0055 - acc: 0.9984 - val_loss: 0.0477 - val_acc: 0.9906\n",
            "Epoch 34/50\n",
            "60000/60000 [==============================] - 6s 102us/step - loss: 0.0045 - acc: 0.9983 - val_loss: 0.0502 - val_acc: 0.9909\n",
            "Epoch 35/50\n",
            "60000/60000 [==============================] - 6s 102us/step - loss: 0.0046 - acc: 0.9986 - val_loss: 0.0510 - val_acc: 0.9897\n",
            "Epoch 36/50\n",
            "60000/60000 [==============================] - 6s 92us/step - loss: 0.0039 - acc: 0.9988 - val_loss: 0.0493 - val_acc: 0.9907\n",
            "Epoch 37/50\n",
            "60000/60000 [==============================] - 6s 93us/step - loss: 0.0059 - acc: 0.9981 - val_loss: 0.0529 - val_acc: 0.9913\n",
            "Epoch 38/50\n",
            "60000/60000 [==============================] - 6s 92us/step - loss: 0.0044 - acc: 0.9988 - val_loss: 0.0527 - val_acc: 0.9898\n",
            "Epoch 39/50\n",
            "60000/60000 [==============================] - 6s 92us/step - loss: 0.0056 - acc: 0.9984 - val_loss: 0.0410 - val_acc: 0.9907\n",
            "Epoch 40/50\n",
            "60000/60000 [==============================] - 6s 93us/step - loss: 0.0022 - acc: 0.9992 - val_loss: 0.0587 - val_acc: 0.9906\n",
            "Epoch 41/50\n",
            "60000/60000 [==============================] - 6s 92us/step - loss: 0.0064 - acc: 0.9980 - val_loss: 0.0533 - val_acc: 0.9897\n",
            "Epoch 42/50\n",
            "60000/60000 [==============================] - 6s 93us/step - loss: 0.0027 - acc: 0.9991 - val_loss: 0.0536 - val_acc: 0.9907\n",
            "Epoch 43/50\n",
            "60000/60000 [==============================] - 6s 92us/step - loss: 0.0039 - acc: 0.9989 - val_loss: 0.0506 - val_acc: 0.9917\n",
            "Epoch 44/50\n",
            "60000/60000 [==============================] - 6s 92us/step - loss: 0.0033 - acc: 0.9991 - val_loss: 0.0711 - val_acc: 0.9892\n",
            "Epoch 45/50\n",
            "60000/60000 [==============================] - 6s 93us/step - loss: 0.0039 - acc: 0.9989 - val_loss: 0.0681 - val_acc: 0.9893\n",
            "Epoch 46/50\n",
            "60000/60000 [==============================] - 6s 94us/step - loss: 0.0048 - acc: 0.9987 - val_loss: 0.0515 - val_acc: 0.9906\n",
            "Epoch 47/50\n",
            "60000/60000 [==============================] - 6s 92us/step - loss: 0.0043 - acc: 0.9985 - val_loss: 0.0509 - val_acc: 0.9907\n",
            "Epoch 48/50\n",
            "60000/60000 [==============================] - 6s 99us/step - loss: 0.0035 - acc: 0.9989 - val_loss: 0.0495 - val_acc: 0.9917\n",
            "Epoch 49/50\n",
            "60000/60000 [==============================] - 6s 104us/step - loss: 0.0036 - acc: 0.9989 - val_loss: 0.0514 - val_acc: 0.9912\n",
            "Epoch 50/50\n",
            "60000/60000 [==============================] - 6s 93us/step - loss: 0.0039 - acc: 0.9988 - val_loss: 0.0488 - val_acc: 0.9921\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fc3cf3a33c8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AtsH-lLk-eLb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "score = model.evaluate(X_test, Y_test, verbose=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mkX8JMv79q9r",
        "colab_type": "code",
        "outputId": "d045a282-d291-4918-d0df-832d2735c8b0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(score)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.04884741170396644, 0.9921]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OCWoJkwE9suh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_pred = model.predict(X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ym7iCFBm9uBs",
        "colab_type": "code",
        "outputId": "95d2fb10-7f41-4c22-b946-ea6992c66d37",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 493
        }
      },
      "source": [
        "print(y_pred[:9])\n",
        "print(y_test[:9])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[3.00416447e-28 6.85400511e-19 4.02430594e-16 1.64819634e-11\n",
            "  8.57887626e-31 4.63110324e-22 0.00000000e+00 1.00000000e+00\n",
            "  2.36470763e-27 9.70309699e-16]\n",
            " [1.35066164e-22 2.47956579e-14 1.00000000e+00 8.92913965e-29\n",
            "  5.25607687e-24 0.00000000e+00 7.59552627e-26 1.51006061e-33\n",
            "  1.91797077e-23 1.23726153e-33]\n",
            " [1.34165321e-24 1.00000000e+00 1.83172738e-14 1.44265572e-15\n",
            "  1.07258450e-17 6.94733247e-16 3.02930167e-18 3.53724819e-12\n",
            "  8.95116636e-15 2.43053251e-24]\n",
            " [1.00000000e+00 7.36552949e-30 4.87615061e-19 1.10784988e-22\n",
            "  2.89815021e-28 2.53736800e-19 1.83953499e-14 8.40072935e-23\n",
            "  2.40251277e-21 5.00091768e-18]\n",
            " [4.36474412e-24 4.96376714e-23 1.17665382e-21 2.09726030e-21\n",
            "  1.00000000e+00 5.89919774e-34 2.61067006e-21 3.63932383e-22\n",
            "  2.09644749e-18 2.76343564e-13]\n",
            " [9.67896959e-21 1.00000000e+00 7.87787283e-12 7.89971658e-13\n",
            "  1.48122213e-16 1.32674936e-19 2.71877271e-20 9.67082595e-11\n",
            "  7.62748222e-14 1.10989604e-24]\n",
            " [0.00000000e+00 5.71746584e-24 9.50201353e-21 3.58857296e-32\n",
            "  1.00000000e+00 5.55287185e-34 0.00000000e+00 2.14777239e-22\n",
            "  1.47664757e-15 9.79234038e-16]\n",
            " [9.14074163e-38 1.63269388e-21 2.62720153e-23 2.54946779e-26\n",
            "  1.68100045e-13 2.20317708e-25 3.07507148e-32 1.83244389e-25\n",
            "  6.41452691e-17 1.00000000e+00]\n",
            " [4.52742791e-18 3.87457792e-28 3.12021930e-20 4.80940000e-23\n",
            "  3.56874771e-28 9.98590291e-01 1.40972598e-03 3.32404097e-28\n",
            "  1.12118535e-11 1.27009013e-13]]\n",
            "[7 2 1 0 4 1 4 9 5]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CT--y98_dr2T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "layer_dict = dict([(layer.name, layer) for layer in model.layers])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2GY4Upv4dsUR",
        "colab_type": "code",
        "outputId": "97f6dff4-e12c-4f8d-bc6a-f240c220dabf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 316
        }
      },
      "source": [
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "from keras import backend as K\n",
        "%matplotlib inline\n",
        "# util function to convert a tensor into a valid image\n",
        "def deprocess_image(x):\n",
        "    # normalize tensor: center on 0., ensure std is 0.1\n",
        "    x -= x.mean()\n",
        "    x /= (x.std() + 1e-5)\n",
        "    x *= 0.1\n",
        "\n",
        "    # clip to [0, 1]\n",
        "    x += 0.5\n",
        "    x = np.clip(x, 0, 1)\n",
        "\n",
        "    # convert to RGB array\n",
        "    x *= 255\n",
        "    #x = x.transpose((1, 2, 0))\n",
        "    x = np.clip(x, 0, 255).astype('uint8')\n",
        "    return x\n",
        "\n",
        "def vis_img_in_filter(img = np.array(X_train[2]).reshape((1, 28, 28, 1)).astype(np.float64), \n",
        "                      layer_name = 'conv2d_14'):\n",
        "    layer_output = layer_dict[layer_name].output\n",
        "    img_ascs = list()\n",
        "    for filter_index in range(layer_output.shape[3]):\n",
        "        # build a loss function that maximizes the activation\n",
        "        # of the nth filter of the layer considered\n",
        "        loss = K.mean(layer_output[:, :, :, filter_index])\n",
        "\n",
        "        # compute the gradient of the input picture wrt this loss\n",
        "        grads = K.gradients(loss, model.input)[0]\n",
        "\n",
        "        # normalization trick: we normalize the gradient\n",
        "        grads /= (K.sqrt(K.mean(K.square(grads))) + 1e-5)\n",
        "\n",
        "        # this function returns the loss and grads given the input picture\n",
        "        iterate = K.function([model.input], [loss, grads])\n",
        "\n",
        "        # step size for gradient ascent\n",
        "        step = 5.\n",
        "\n",
        "        img_asc = np.array(img)\n",
        "        # run gradient ascent for 20 steps\n",
        "        for i in range(20):\n",
        "            loss_value, grads_value = iterate([img_asc])\n",
        "            img_asc += grads_value * step\n",
        "\n",
        "        img_asc = img_asc[0]\n",
        "        img_ascs.append(deprocess_image(img_asc).reshape((28, 28)))\n",
        "        \n",
        "    if layer_output.shape[3] >= 35:\n",
        "        plot_x, plot_y = 6, 6\n",
        "    elif layer_output.shape[3] >= 23:\n",
        "        plot_x, plot_y = 4, 6\n",
        "    elif layer_output.shape[3] >= 11:\n",
        "        plot_x, plot_y = 2, 6\n",
        "    else:\n",
        "        plot_x, plot_y = 1, 2\n",
        "    fig, ax = plt.subplots(plot_x, plot_y, figsize = (12, 12))\n",
        "    ax[0, 0].imshow(img.reshape((28, 28)), cmap = 'gray')\n",
        "    ax[0, 0].set_title('Input image')\n",
        "    fig.suptitle('Input image and %s filters' % (layer_name,))\n",
        "    fig.tight_layout(pad = 0.3, rect = [0, 0, 0.9, 0.9])\n",
        "    for (x, y) in [(i, j) for i in range(plot_x) for j in range(plot_y)]:\n",
        "        if x == 0 and y == 0:\n",
        "            continue\n",
        "        ax[x, y].imshow(img_ascs[x * plot_y + y - 1], cmap = 'gray')\n",
        "        ax[x, y].set_title('filter %d' % (x * plot_y + y - 1))\n",
        "\n",
        "vis_img_in_filter()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-19229f66b51a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     69\u001b[0m         \u001b[0max\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_title\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'filter %d'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mplot_y\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m \u001b[0mvis_img_in_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-19-19229f66b51a>\u001b[0m in \u001b[0;36mvis_img_in_filter\u001b[0;34m(img, layer_name)\u001b[0m\n\u001b[1;32m     22\u001b[0m def vis_img_in_filter(img = np.array(X_train[2]).reshape((1, 28, 28, 1)).astype(np.float64), \n\u001b[1;32m     23\u001b[0m                       layer_name = 'conv2d_14'):\n\u001b[0;32m---> 24\u001b[0;31m     \u001b[0mlayer_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlayer_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m     \u001b[0mimg_ascs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mfilter_index\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'conv2d_14'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9tvptcn8dxvp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}
