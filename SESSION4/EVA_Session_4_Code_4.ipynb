{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "EVA_Session_4_4.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vC1KGoWe6Rcw",
        "colab_type": "text"
      },
      "source": [
        "##Fourth Iteration"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aNyZv-Ec52ot",
        "colab_type": "text"
      },
      "source": [
        "### **Import Libraries and modules**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3m3w1Cw49Zkt",
        "colab_type": "code",
        "outputId": "29dd53e7-ab1f-4f60-f0f9-db045895fb24",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# https://keras.io/\n",
        "!pip install -q keras\n",
        "import keras"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Eso6UHE080D4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten, Add\n",
        "from keras.layers import Convolution2D, MaxPooling2D\n",
        "from keras.utils import np_utils\n",
        "\n",
        "from keras.datasets import mnist"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zByEi95J86RD",
        "colab_type": "text"
      },
      "source": [
        "### Load pre-shuffled MNIST data into train and test sets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7eRM0QWN83PV",
        "colab_type": "code",
        "outputId": "68f3ae61-aff7-4cdd-b937-83125eaaf3e1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://s3.amazonaws.com/img-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lqHhymamBXle",
        "colab_type": "text"
      },
      "source": [
        "###Analyzing mnist dataset \n",
        "To proceed further with the convoution, it is always necessary to have a better understanding of how the dataset looks and what could be the prediction dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4a4Be72j8-ZC",
        "colab_type": "code",
        "outputId": "93927364-1401-4cfa-9333-dd98ba2c2868",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 303
        }
      },
      "source": [
        "print (X_train.shape)\n",
        "from matplotlib import pyplot as plt\n",
        "%matplotlib inline\n",
        "plt.imshow(X_train[0])\n",
        "plt.imshow(X_train[15])\n",
        "plt.imshow(X_train[500])\n",
        "plt.imshow(X_train[3000])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(60000, 28, 28)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f29dfb703c8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_E8ZL9z9DijO",
        "colab_type": "text"
      },
      "source": [
        "###Data Pre-Processing\n",
        "\n",
        "Now we need to reshape the images as the model expects. The last number 1 signifies that the image is in greyscale."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dkmprriw9AnZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train = X_train.reshape(X_train.shape[0], 28, 28,1)\n",
        "X_test = X_test.reshape(X_test.shape[0], 28, 28,1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X2m4YS4E9CRh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train = X_train.astype('float32')\n",
        "X_test = X_test.astype('float32')\n",
        "X_train /= 255\n",
        "X_test /= 255"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ny1tpyKVHUJt",
        "colab_type": "text"
      },
      "source": [
        "We also need to analyzing the Class array and 'one-hot-encode' them to so that our model could make more sense out of it. \n",
        "\n",
        "We can see the sample of class array below:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Mn0vAYD9DvB",
        "colab_type": "code",
        "outputId": "abc357f1-a879-4723-b8d9-97803fdac190",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "y_train[:10]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([5, 0, 4, 1, 9, 2, 1, 3, 1, 4], dtype=uint8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZG8JiXR39FHC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Convert 1-dimensional class arrays to 10-dimensional class matrices\n",
        "Y_train = np_utils.to_categorical(y_train, 10)\n",
        "Y_test = np_utils.to_categorical(y_test, 10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i-vlW_LhH-yA",
        "colab_type": "text"
      },
      "source": [
        "after processing, we can see that the value of 5 is replaced by an array which signifies its value by keeping 1 in the 6th place (array starts by index 0) and rest of the array as 0."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fYlFRvKS9HMB",
        "colab_type": "code",
        "outputId": "2a9f2adb-6abd-4e24-a172-4a8a117e1393",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "Y_train[:10]\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
              "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
              "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
              "       [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N7iYzvebJDrl",
        "colab_type": "text"
      },
      "source": [
        "###Building the Model\n",
        "\n",
        "###UPDATE from Third Iteration:\n",
        "\n",
        "We have again made 2 updates on the Third iteration:\n",
        "- reduced the number of channels in \"layer 5\" to 10 channels so that we can keep the number of parameters beow 15000.\n",
        "- We are now set the learning rate to 0.003 and reducing at a steady on every epoch."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "osKqT73Q9JJB",
        "colab_type": "code",
        "outputId": "6df4b800-22d0-44c8-c71a-f9701a298d11",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 292
        }
      },
      "source": [
        "from keras.layers import Activation, BatchNormalization\n",
        "model = Sequential()\n",
        "\n",
        " \n",
        "model.add(Convolution2D(10, 3, 3, activation='relu', input_shape=(28,28,1))) # 26\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.1))\n",
        "\n",
        "model.add(Convolution2D(16, 3, 3, activation='relu')) # 22\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.1))\n",
        "\n",
        "model.add(Convolution2D(32, 3, 3, activation='relu')) # 9\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.1))\n",
        "\n",
        "model.add(MaxPooling2D(pool_size=(2, 2))) # 11\n",
        "model.add(Convolution2D(16, 1, 1, activation='relu')) # 11\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.1))\n",
        "\n",
        "model.add(Convolution2D(10, 3, 3, activation='relu')) # 7\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.1))\n",
        "\n",
        "model.add(Convolution2D(10, 3, 3, activation='relu')) # 7\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.1))\n",
        "\n",
        "model.add(Convolution2D(10, 1, activation='relu')) #7\n",
        "# model.add(BatchNormalization())\n",
        "# model.add(Dropout(0.1))\n",
        "\n",
        "model.add(Convolution2D(10, 7))\n",
        "model.add(Flatten())\n",
        "model.add(Activation('softmax'))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:5: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(10, (3, 3), activation=\"relu\", input_shape=(28, 28, 1...)`\n",
            "  \"\"\"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:9: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, (3, 3), activation=\"relu\")`\n",
            "  if __name__ == '__main__':\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:13: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), activation=\"relu\")`\n",
            "  del sys.path[0]\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:18: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, (1, 1), activation=\"relu\")`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:22: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(10, (3, 3), activation=\"relu\")`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:26: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(10, (3, 3), activation=\"relu\")`\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z7FIvsSjvYKN",
        "colab_type": "code",
        "outputId": "c4620004-966a-4f47-f765-097de164f90e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 918
        }
      },
      "source": [
        "model.summary() "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_1 (Conv2D)            (None, 26, 26, 10)        100       \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 26, 26, 10)        40        \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 26, 26, 10)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 24, 24, 16)        1456      \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 24, 24, 16)        64        \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 24, 24, 16)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 22, 22, 32)        4640      \n",
            "_________________________________________________________________\n",
            "batch_normalization_3 (Batch (None, 22, 22, 32)        128       \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 22, 22, 32)        0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 11, 11, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_4 (Conv2D)            (None, 11, 11, 16)        528       \n",
            "_________________________________________________________________\n",
            "batch_normalization_4 (Batch (None, 11, 11, 16)        64        \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 11, 11, 16)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_5 (Conv2D)            (None, 9, 9, 10)          1450      \n",
            "_________________________________________________________________\n",
            "batch_normalization_5 (Batch (None, 9, 9, 10)          40        \n",
            "_________________________________________________________________\n",
            "dropout_5 (Dropout)          (None, 9, 9, 10)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_6 (Conv2D)            (None, 7, 7, 10)          910       \n",
            "_________________________________________________________________\n",
            "batch_normalization_6 (Batch (None, 7, 7, 10)          40        \n",
            "_________________________________________________________________\n",
            "dropout_6 (Dropout)          (None, 7, 7, 10)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_7 (Conv2D)            (None, 7, 7, 10)          110       \n",
            "_________________________________________________________________\n",
            "conv2d_8 (Conv2D)            (None, 1, 1, 10)          4910      \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 10)                0         \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 10)                0         \n",
            "=================================================================\n",
            "Total params: 14,480\n",
            "Trainable params: 14,292\n",
            "Non-trainable params: 188\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G7AUNI9QHnKE",
        "colab_type": "text"
      },
      "source": [
        "###Compiling the model\n",
        "\n",
        "Here I am using *adam* optimizer, where I have also used the learning rate 0.002 an momentum as 0.9 so that the model converges slowly to the minima and we see less variance in the accuracy after each epoch."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zp6SuGrL9M3h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.optimizers import Adam\n",
        "from keras.callbacks import LearningRateScheduler\n",
        "\n",
        "def scheduler(epoch, lr):\n",
        "  return round(0.003*1/(1+.319*epoch),10)\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "             optimizer=Adam(lr=0.003),\n",
        "             metrics=['accuracy'])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iNhc--VrIgNg",
        "colab_type": "text"
      },
      "source": [
        "###Training the model\n",
        "\n",
        "### \\*Observation while comparing Third and Fourth code:\n",
        "Setting the learning rate has improved the model and we have been able to reach 99.4% accuracy a lot faster and less variation.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4xWoKhPY9Of5",
        "colab_type": "code",
        "outputId": "cb843fdf-f311-4019-9a82-ef9d3c471863",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 3556
        }
      },
      "source": [
        "model.fit(X_train, Y_train, batch_size=128, nb_epoch=50, verbose=1, validation_data=(X_test,Y_test), callbacks=[LearningRateScheduler(scheduler,verbose=1)])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/50\n",
            "\n",
            "Epoch 00001: LearningRateScheduler setting learning rate to 0.003.\n",
            "60000/60000 [==============================] - 15s 246us/step - loss: 0.1699 - acc: 0.9462 - val_loss: 0.0645 - val_acc: 0.9784\n",
            "Epoch 2/50\n",
            "\n",
            "Epoch 00002: LearningRateScheduler setting learning rate to 0.0022744503.\n",
            "60000/60000 [==============================] - 11s 183us/step - loss: 0.0615 - acc: 0.9806 - val_loss: 0.0347 - val_acc: 0.9887\n",
            "Epoch 3/50\n",
            "\n",
            "Epoch 00003: LearningRateScheduler setting learning rate to 0.0018315018.\n",
            "60000/60000 [==============================] - 12s 195us/step - loss: 0.0494 - acc: 0.9844 - val_loss: 0.0338 - val_acc: 0.9880\n",
            "Epoch 4/50\n",
            "\n",
            "Epoch 00004: LearningRateScheduler setting learning rate to 0.0015329586.\n",
            "60000/60000 [==============================] - 11s 183us/step - loss: 0.0405 - acc: 0.9872 - val_loss: 0.0268 - val_acc: 0.9914\n",
            "Epoch 5/50\n",
            "\n",
            "Epoch 00005: LearningRateScheduler setting learning rate to 0.0013181019.\n",
            "60000/60000 [==============================] - 11s 182us/step - loss: 0.0358 - acc: 0.9885 - val_loss: 0.0315 - val_acc: 0.9897\n",
            "Epoch 6/50\n",
            "\n",
            "Epoch 00006: LearningRateScheduler setting learning rate to 0.0011560694.\n",
            "60000/60000 [==============================] - 11s 190us/step - loss: 0.0324 - acc: 0.9899 - val_loss: 0.0255 - val_acc: 0.9923\n",
            "Epoch 7/50\n",
            "\n",
            "Epoch 00007: LearningRateScheduler setting learning rate to 0.0010295127.\n",
            "60000/60000 [==============================] - 12s 194us/step - loss: 0.0305 - acc: 0.9903 - val_loss: 0.0245 - val_acc: 0.9911\n",
            "Epoch 8/50\n",
            "\n",
            "Epoch 00008: LearningRateScheduler setting learning rate to 0.0009279307.\n",
            "60000/60000 [==============================] - 11s 182us/step - loss: 0.0266 - acc: 0.9914 - val_loss: 0.0219 - val_acc: 0.9927\n",
            "Epoch 9/50\n",
            "\n",
            "Epoch 00009: LearningRateScheduler setting learning rate to 0.0008445946.\n",
            "60000/60000 [==============================] - 11s 181us/step - loss: 0.0269 - acc: 0.9912 - val_loss: 0.0230 - val_acc: 0.9923\n",
            "Epoch 10/50\n",
            "\n",
            "Epoch 00010: LearningRateScheduler setting learning rate to 0.0007749935.\n",
            "60000/60000 [==============================] - 11s 191us/step - loss: 0.0237 - acc: 0.9919 - val_loss: 0.0200 - val_acc: 0.9931\n",
            "Epoch 11/50\n",
            "\n",
            "Epoch 00011: LearningRateScheduler setting learning rate to 0.0007159905.\n",
            "60000/60000 [==============================] - 11s 185us/step - loss: 0.0234 - acc: 0.9920 - val_loss: 0.0208 - val_acc: 0.9936\n",
            "Epoch 12/50\n",
            "\n",
            "Epoch 00012: LearningRateScheduler setting learning rate to 0.000665336.\n",
            "60000/60000 [==============================] - 11s 180us/step - loss: 0.0211 - acc: 0.9931 - val_loss: 0.0210 - val_acc: 0.9929\n",
            "Epoch 13/50\n",
            "\n",
            "Epoch 00013: LearningRateScheduler setting learning rate to 0.0006213753.\n",
            "60000/60000 [==============================] - 11s 181us/step - loss: 0.0204 - acc: 0.9930 - val_loss: 0.0203 - val_acc: 0.9933\n",
            "Epoch 14/50\n",
            "\n",
            "Epoch 00014: LearningRateScheduler setting learning rate to 0.0005828638.\n",
            "60000/60000 [==============================] - 11s 180us/step - loss: 0.0195 - acc: 0.9936 - val_loss: 0.0214 - val_acc: 0.9932\n",
            "Epoch 15/50\n",
            "\n",
            "Epoch 00015: LearningRateScheduler setting learning rate to 0.0005488474.\n",
            "60000/60000 [==============================] - 11s 183us/step - loss: 0.0193 - acc: 0.9936 - val_loss: 0.0212 - val_acc: 0.9929\n",
            "Epoch 16/50\n",
            "\n",
            "Epoch 00016: LearningRateScheduler setting learning rate to 0.0005185825.\n",
            "60000/60000 [==============================] - 11s 184us/step - loss: 0.0175 - acc: 0.9941 - val_loss: 0.0196 - val_acc: 0.9943\n",
            "Epoch 17/50\n",
            "\n",
            "Epoch 00017: LearningRateScheduler setting learning rate to 0.000491481.\n",
            "60000/60000 [==============================] - 11s 185us/step - loss: 0.0178 - acc: 0.9940 - val_loss: 0.0218 - val_acc: 0.9936\n",
            "Epoch 18/50\n",
            "\n",
            "Epoch 00018: LearningRateScheduler setting learning rate to 0.0004670715.\n",
            "60000/60000 [==============================] - 11s 188us/step - loss: 0.0164 - acc: 0.9943 - val_loss: 0.0212 - val_acc: 0.9934\n",
            "Epoch 19/50\n",
            "\n",
            "Epoch 00019: LearningRateScheduler setting learning rate to 0.0004449718.\n",
            "60000/60000 [==============================] - 11s 178us/step - loss: 0.0161 - acc: 0.9946 - val_loss: 0.0231 - val_acc: 0.9929\n",
            "Epoch 20/50\n",
            "\n",
            "Epoch 00020: LearningRateScheduler setting learning rate to 0.000424869.\n",
            "60000/60000 [==============================] - 11s 178us/step - loss: 0.0156 - acc: 0.9948 - val_loss: 0.0209 - val_acc: 0.9934\n",
            "Epoch 21/50\n",
            "\n",
            "Epoch 00021: LearningRateScheduler setting learning rate to 0.0004065041.\n",
            "60000/60000 [==============================] - 11s 179us/step - loss: 0.0159 - acc: 0.9944 - val_loss: 0.0218 - val_acc: 0.9936\n",
            "Epoch 22/50\n",
            "\n",
            "Epoch 00022: LearningRateScheduler setting learning rate to 0.000389661.\n",
            "60000/60000 [==============================] - 11s 183us/step - loss: 0.0149 - acc: 0.9948 - val_loss: 0.0201 - val_acc: 0.9933\n",
            "Epoch 23/50\n",
            "\n",
            "Epoch 00023: LearningRateScheduler setting learning rate to 0.0003741581.\n",
            "60000/60000 [==============================] - 11s 182us/step - loss: 0.0139 - acc: 0.9953 - val_loss: 0.0192 - val_acc: 0.9940\n",
            "Epoch 24/50\n",
            "\n",
            "Epoch 00024: LearningRateScheduler setting learning rate to 0.0003598417.\n",
            "60000/60000 [==============================] - 11s 181us/step - loss: 0.0148 - acc: 0.9948 - val_loss: 0.0200 - val_acc: 0.9937\n",
            "Epoch 25/50\n",
            "\n",
            "Epoch 00025: LearningRateScheduler setting learning rate to 0.0003465804.\n",
            "60000/60000 [==============================] - 12s 196us/step - loss: 0.0140 - acc: 0.9952 - val_loss: 0.0203 - val_acc: 0.9936\n",
            "Epoch 26/50\n",
            "\n",
            "Epoch 00026: LearningRateScheduler setting learning rate to 0.0003342618.\n",
            "60000/60000 [==============================] - 11s 186us/step - loss: 0.0139 - acc: 0.9953 - val_loss: 0.0185 - val_acc: 0.9946\n",
            "Epoch 27/50\n",
            "\n",
            "Epoch 00027: LearningRateScheduler setting learning rate to 0.0003227889.\n",
            "60000/60000 [==============================] - 11s 184us/step - loss: 0.0143 - acc: 0.9952 - val_loss: 0.0195 - val_acc: 0.9943\n",
            "Epoch 28/50\n",
            "\n",
            "Epoch 00028: LearningRateScheduler setting learning rate to 0.0003120774.\n",
            "60000/60000 [==============================] - 11s 180us/step - loss: 0.0138 - acc: 0.9954 - val_loss: 0.0203 - val_acc: 0.9935\n",
            "Epoch 29/50\n",
            "\n",
            "Epoch 00029: LearningRateScheduler setting learning rate to 0.000302054.\n",
            "60000/60000 [==============================] - 11s 178us/step - loss: 0.0136 - acc: 0.9954 - val_loss: 0.0201 - val_acc: 0.9944\n",
            "Epoch 30/50\n",
            "\n",
            "Epoch 00030: LearningRateScheduler setting learning rate to 0.0002926544.\n",
            "60000/60000 [==============================] - 11s 179us/step - loss: 0.0117 - acc: 0.9963 - val_loss: 0.0208 - val_acc: 0.9940\n",
            "Epoch 31/50\n",
            "\n",
            "Epoch 00031: LearningRateScheduler setting learning rate to 0.0002838221.\n",
            "60000/60000 [==============================] - 11s 179us/step - loss: 0.0135 - acc: 0.9955 - val_loss: 0.0199 - val_acc: 0.9940\n",
            "Epoch 32/50\n",
            "\n",
            "Epoch 00032: LearningRateScheduler setting learning rate to 0.0002755074.\n",
            "60000/60000 [==============================] - 11s 189us/step - loss: 0.0121 - acc: 0.9959 - val_loss: 0.0193 - val_acc: 0.9948\n",
            "Epoch 33/50\n",
            "\n",
            "Epoch 00033: LearningRateScheduler setting learning rate to 0.000267666.\n",
            "60000/60000 [==============================] - 11s 184us/step - loss: 0.0122 - acc: 0.9959 - val_loss: 0.0192 - val_acc: 0.9944\n",
            "Epoch 34/50\n",
            "\n",
            "Epoch 00034: LearningRateScheduler setting learning rate to 0.0002602585.\n",
            "60000/60000 [==============================] - 11s 183us/step - loss: 0.0117 - acc: 0.9960 - val_loss: 0.0198 - val_acc: 0.9946\n",
            "Epoch 35/50\n",
            "\n",
            "Epoch 00035: LearningRateScheduler setting learning rate to 0.00025325.\n",
            "60000/60000 [==============================] - 12s 198us/step - loss: 0.0116 - acc: 0.9961 - val_loss: 0.0186 - val_acc: 0.9946\n",
            "Epoch 36/50\n",
            "\n",
            "Epoch 00036: LearningRateScheduler setting learning rate to 0.0002466091.\n",
            "60000/60000 [==============================] - 11s 180us/step - loss: 0.0113 - acc: 0.9961 - val_loss: 0.0192 - val_acc: 0.9947\n",
            "Epoch 37/50\n",
            "\n",
            "Epoch 00037: LearningRateScheduler setting learning rate to 0.0002403076.\n",
            "60000/60000 [==============================] - 11s 179us/step - loss: 0.0113 - acc: 0.9961 - val_loss: 0.0202 - val_acc: 0.9948\n",
            "Epoch 38/50\n",
            "\n",
            "Epoch 00038: LearningRateScheduler setting learning rate to 0.0002343201.\n",
            "60000/60000 [==============================] - 11s 180us/step - loss: 0.0112 - acc: 0.9962 - val_loss: 0.0202 - val_acc: 0.9946\n",
            "Epoch 39/50\n",
            "\n",
            "Epoch 00039: LearningRateScheduler setting learning rate to 0.0002286237.\n",
            "60000/60000 [==============================] - 11s 185us/step - loss: 0.0109 - acc: 0.9965 - val_loss: 0.0192 - val_acc: 0.9946\n",
            "Epoch 40/50\n",
            "\n",
            "Epoch 00040: LearningRateScheduler setting learning rate to 0.0002231977.\n",
            "60000/60000 [==============================] - 11s 187us/step - loss: 0.0112 - acc: 0.9962 - val_loss: 0.0202 - val_acc: 0.9947\n",
            "Epoch 41/50\n",
            "\n",
            "Epoch 00041: LearningRateScheduler setting learning rate to 0.0002180233.\n",
            "60000/60000 [==============================] - 11s 178us/step - loss: 0.0112 - acc: 0.9962 - val_loss: 0.0200 - val_acc: 0.9948\n",
            "Epoch 42/50\n",
            "\n",
            "Epoch 00042: LearningRateScheduler setting learning rate to 0.0002130833.\n",
            "60000/60000 [==============================] - 11s 179us/step - loss: 0.0104 - acc: 0.9964 - val_loss: 0.0204 - val_acc: 0.9946\n",
            "Epoch 43/50\n",
            "\n",
            "Epoch 00043: LearningRateScheduler setting learning rate to 0.0002083623.\n",
            "60000/60000 [==============================] - 11s 187us/step - loss: 0.0105 - acc: 0.9965 - val_loss: 0.0200 - val_acc: 0.9947\n",
            "Epoch 44/50\n",
            "\n",
            "Epoch 00044: LearningRateScheduler setting learning rate to 0.0002038459.\n",
            "60000/60000 [==============================] - 11s 179us/step - loss: 0.0110 - acc: 0.9963 - val_loss: 0.0205 - val_acc: 0.9949\n",
            "Epoch 45/50\n",
            "\n",
            "Epoch 00045: LearningRateScheduler setting learning rate to 0.0001995211.\n",
            "60000/60000 [==============================] - 11s 180us/step - loss: 0.0098 - acc: 0.9967 - val_loss: 0.0200 - val_acc: 0.9947\n",
            "Epoch 46/50\n",
            "\n",
            "Epoch 00046: LearningRateScheduler setting learning rate to 0.0001953761.\n",
            "60000/60000 [==============================] - 11s 179us/step - loss: 0.0105 - acc: 0.9965 - val_loss: 0.0207 - val_acc: 0.9945\n",
            "Epoch 47/50\n",
            "\n",
            "Epoch 00047: LearningRateScheduler setting learning rate to 0.0001913998.\n",
            "60000/60000 [==============================] - 12s 194us/step - loss: 0.0108 - acc: 0.9962 - val_loss: 0.0195 - val_acc: 0.9946\n",
            "Epoch 48/50\n",
            "\n",
            "Epoch 00048: LearningRateScheduler setting learning rate to 0.0001875821.\n",
            "60000/60000 [==============================] - 11s 179us/step - loss: 0.0110 - acc: 0.9962 - val_loss: 0.0199 - val_acc: 0.9944\n",
            "Epoch 49/50\n",
            "\n",
            "Epoch 00049: LearningRateScheduler setting learning rate to 0.0001839137.\n",
            "60000/60000 [==============================] - 11s 179us/step - loss: 0.0092 - acc: 0.9969 - val_loss: 0.0213 - val_acc: 0.9945\n",
            "Epoch 50/50\n",
            "\n",
            "Epoch 00050: LearningRateScheduler setting learning rate to 0.000180386.\n",
            "60000/60000 [==============================] - 11s 179us/step - loss: 0.0102 - acc: 0.9965 - val_loss: 0.0208 - val_acc: 0.9946\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f29dfb4dc18>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AtsH-lLk-eLb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "score = model.evaluate(X_test, Y_test, verbose=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mkX8JMv79q9r",
        "colab_type": "code",
        "outputId": "b3f13d46-2a70-43e1-ddd2-a76b59f6f59c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(score)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.020771510967807626, 0.9946]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OCWoJkwE9suh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_pred = model.predict(X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ym7iCFBm9uBs",
        "colab_type": "code",
        "outputId": "199c7478-7cba-47dd-d526-ba7cd99b9a16",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 493
        }
      },
      "source": [
        "print(y_pred[:9])\n",
        "print(y_test[:9])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[3.40398255e-13 2.48331938e-10 2.63144422e-08 1.35774514e-09\n",
            "  5.26372802e-14 2.27463031e-11 9.69505805e-18 1.00000000e+00\n",
            "  1.20314678e-11 4.24191215e-09]\n",
            " [1.06890127e-07 1.59885204e-07 9.99999762e-01 1.28674293e-13\n",
            "  9.83331472e-11 7.76047254e-19 3.13921500e-10 1.02553260e-13\n",
            "  8.23621865e-11 2.71499742e-14]\n",
            " [1.12317837e-12 9.99999642e-01 9.15912857e-09 2.38062885e-11\n",
            "  1.95334650e-07 1.04825322e-10 3.19811688e-09 1.55970916e-08\n",
            "  9.06434749e-08 7.92784671e-10]\n",
            " [1.00000000e+00 9.01806002e-17 4.05548928e-09 4.82971326e-15\n",
            "  6.23585439e-13 1.24647471e-12 4.47367654e-08 8.53263298e-15\n",
            "  4.46171899e-09 3.14708759e-10]\n",
            " [2.85665480e-12 4.41827477e-12 7.17896520e-10 9.18144341e-17\n",
            "  9.99999523e-01 3.54376478e-15 4.96636640e-13 8.82050130e-13\n",
            "  2.38626566e-11 4.99856867e-07]\n",
            " [6.08745433e-12 9.99999762e-01 8.55576676e-09 6.65004144e-14\n",
            "  2.12586144e-07 1.88923985e-12 1.44366658e-10 5.39563452e-08\n",
            "  2.98624281e-09 2.27440666e-09]\n",
            " [1.78242235e-19 2.35576645e-11 1.42126927e-11 2.14650876e-15\n",
            "  9.99999166e-01 4.91413576e-16 1.11142800e-18 2.90360500e-08\n",
            "  7.84762904e-07 7.89474441e-08]\n",
            " [5.80556328e-13 2.16131149e-12 1.05146482e-11 1.03755129e-11\n",
            "  1.15884295e-05 3.33931841e-11 3.23073533e-16 8.03334482e-11\n",
            "  1.51986370e-08 9.99988437e-01]\n",
            " [4.19952828e-09 2.14574579e-15 7.27495321e-13 8.29865274e-11\n",
            "  3.44044536e-13 9.59900498e-01 4.00987789e-02 1.23199076e-16\n",
            "  6.26265887e-07 7.08715486e-09]]\n",
            "[7 2 1 0 4 1 4 9 5]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CT--y98_dr2T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "layer_dict = dict([(layer.name, layer) for layer in model.layers])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2GY4Upv4dsUR",
        "colab_type": "code",
        "outputId": "d5de30b4-76a7-45f9-aa85-4f1195407c90",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 316
        }
      },
      "source": [
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "from keras import backend as K\n",
        "%matplotlib inline\n",
        "# util function to convert a tensor into a valid image\n",
        "def deprocess_image(x):\n",
        "    # normalize tensor: center on 0., ensure std is 0.1\n",
        "    x -= x.mean()\n",
        "    x /= (x.std() + 1e-5)\n",
        "    x *= 0.1\n",
        "\n",
        "    # clip to [0, 1]\n",
        "    x += 0.5\n",
        "    x = np.clip(x, 0, 1)\n",
        "\n",
        "    # convert to RGB array\n",
        "    x *= 255\n",
        "    #x = x.transpose((1, 2, 0))\n",
        "    x = np.clip(x, 0, 255).astype('uint8')\n",
        "    return x\n",
        "\n",
        "def vis_img_in_filter(img = np.array(X_train[2]).reshape((1, 28, 28, 1)).astype(np.float64), \n",
        "                      layer_name = 'conv2d_14'):\n",
        "    layer_output = layer_dict[layer_name].output\n",
        "    img_ascs = list()\n",
        "    for filter_index in range(layer_output.shape[3]):\n",
        "        # build a loss function that maximizes the activation\n",
        "        # of the nth filter of the layer considered\n",
        "        loss = K.mean(layer_output[:, :, :, filter_index])\n",
        "\n",
        "        # compute the gradient of the input picture wrt this loss\n",
        "        grads = K.gradients(loss, model.input)[0]\n",
        "\n",
        "        # normalization trick: we normalize the gradient\n",
        "        grads /= (K.sqrt(K.mean(K.square(grads))) + 1e-5)\n",
        "\n",
        "        # this function returns the loss and grads given the input picture\n",
        "        iterate = K.function([model.input], [loss, grads])\n",
        "\n",
        "        # step size for gradient ascent\n",
        "        step = 5.\n",
        "\n",
        "        img_asc = np.array(img)\n",
        "        # run gradient ascent for 20 steps\n",
        "        for i in range(20):\n",
        "            loss_value, grads_value = iterate([img_asc])\n",
        "            img_asc += grads_value * step\n",
        "\n",
        "        img_asc = img_asc[0]\n",
        "        img_ascs.append(deprocess_image(img_asc).reshape((28, 28)))\n",
        "        \n",
        "    if layer_output.shape[3] >= 35:\n",
        "        plot_x, plot_y = 6, 6\n",
        "    elif layer_output.shape[3] >= 23:\n",
        "        plot_x, plot_y = 4, 6\n",
        "    elif layer_output.shape[3] >= 11:\n",
        "        plot_x, plot_y = 2, 6\n",
        "    else:\n",
        "        plot_x, plot_y = 1, 2\n",
        "    fig, ax = plt.subplots(plot_x, plot_y, figsize = (12, 12))\n",
        "    ax[0, 0].imshow(img.reshape((28, 28)), cmap = 'gray')\n",
        "    ax[0, 0].set_title('Input image')\n",
        "    fig.suptitle('Input image and %s filters' % (layer_name,))\n",
        "    fig.tight_layout(pad = 0.3, rect = [0, 0, 0.9, 0.9])\n",
        "    for (x, y) in [(i, j) for i in range(plot_x) for j in range(plot_y)]:\n",
        "        if x == 0 and y == 0:\n",
        "            continue\n",
        "        ax[x, y].imshow(img_ascs[x * plot_y + y - 1], cmap = 'gray')\n",
        "        ax[x, y].set_title('filter %d' % (x * plot_y + y - 1))\n",
        "\n",
        "vis_img_in_filter()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-19229f66b51a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     69\u001b[0m         \u001b[0max\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_title\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'filter %d'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mplot_y\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m \u001b[0mvis_img_in_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-19-19229f66b51a>\u001b[0m in \u001b[0;36mvis_img_in_filter\u001b[0;34m(img, layer_name)\u001b[0m\n\u001b[1;32m     22\u001b[0m def vis_img_in_filter(img = np.array(X_train[2]).reshape((1, 28, 28, 1)).astype(np.float64), \n\u001b[1;32m     23\u001b[0m                       layer_name = 'conv2d_14'):\n\u001b[0;32m---> 24\u001b[0;31m     \u001b[0mlayer_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlayer_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m     \u001b[0mimg_ascs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mfilter_index\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'conv2d_14'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9tvptcn8dxvp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}
